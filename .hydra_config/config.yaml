defaults:
  - _self_  # TODO: Silences the hydra version migration warning (PLEASE REVIEW FOR BREAKING CHANGES)
  - chunker: recursive_splitter #semantic_splitter
  - retriever: multiQuery
  - rag: ChatBotRag

llm_params: &llm_params
  temperature: 0.2
  timeout: 60
  max_retries: 2
  frequency_penalty: 0.2

llm:
  <<: *llm_params
  base_url: ${oc.env:BASE_URL}
  model: ${oc.env:MODEL}
  api_key: ${oc.env:API_KEY}

vlm:
  <<: *llm_params
  base_url: ${oc.env:VLM_BASE_URL}
  model: ${oc.env:VLM_MODEL}  
  api_key: ${oc.env:VLM_API_KEY}

embedder:
  type: huggingface
  model_name: ${oc.env:EMBEDDER_MODEL_NAME, HIT-TMG/KaLM-embedding-multilingual-mini-v1}
  
vectordb:
  host: ${oc.env:VDB_HOST, milvus}
  port: ${oc.env:VDB_PORT, 19530}
  connector_name: ${oc.env:VDB_CONNECTOR_NAME, milvus}
  collection_name: vdb 
  hybrid_mode: true
  enable: true

insertion:
  n_concurrent_loading: 2 # Number of concurrent loading operations (2-3 is recommended, knowing that some loaders use gpu)
  n_concurrent_chunking: 2 # Number of concurrent chunking operations

reranker:
  enable: ${oc.decode:${oc.env:RERANKER_ENABLED, true}}
  model_name: ${oc.env:RERANKER_MODEL, jinaai/jina-colbert-v2}
  top_k: ${oc.decode:${oc.env:RERANKER_TOP_K, 4}}

grader:
  enable: false

verbose:
  verbose: true
  level: INFO

paths:
  prompts_dir: ${oc.env:PROMPTS_DIR, ../prompts}
  data_dir: ${oc.env:DATA_DIR, ../data}

prompt:
  rag_sys_pmpt: rag_sys_prompt_template.txt # rag_sys_pmpt_tmpl_ifa.txt
  context_pmpt_tmpl: contextualize_prompt_template.txt

loader:
  image_captioning: true
  file_loaders:
    docx: MarkItDownLoader
    pdf: ${oc.env:PDFLoader, DoclingLoader}  # DoclingLoader # MarkerLoader # CustomPyMuPDFLoader # Custompymupdf4llm
    doc: DocLoader
    pptx: PPTXLoader
    txt: TextLoader

semaphore:
  llm_semaphore: ${oc.decode:${oc.env:LLM_SEMAPHORE, 10}}